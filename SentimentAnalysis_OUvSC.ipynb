{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "678ef711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 7.7.1 of praw is outdated. Version 7.8.0 was released 4 days ago.\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id='',\n",
    "    client_secret='',\n",
    "    user_agent=''\n",
    "\n",
    ")\n",
    "\n",
    "print(reddit.read_only)  # Should print True if it works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cfeca17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Title: Game thread - South Carolina (3-3) @ Oklahoma (4-2) on Oct 19th, 11:45am CDT\n",
      "\n",
      "i think we miss a bowl if we lose this game lol\n",
      "...and the very first play is an interception. Jesus...\n",
      "It just keeps getting worse somehow lmao\n",
      "I would say put Arnold back in, but I‚Äôm not sure Baker Mayfield could function with these scrubs around him. Absolutely pathetic\n",
      "If people don‚Äôt get fired after this, we aren‚Äôt serious about being good.\n",
      "Defense has played 5 snaps and we‚Äôre down 0-21‚Ä¶ what now Brent?!?? Is this the confirmation you needed to make an offensive coaching change?!\n",
      "I honestly would like to see this continue to be an abysmally bad game. I know that sounds crass but we know what we have staff-wise is not the answer and this would help speed up the process of firing some people (especially Litrell)\n",
      "This is rock bottom\n",
      "Remember when we used to mock Texas for constantly firing head coaches? Doesn't seem so foolish now, does it?\n",
      "When was the last time we got our assses kicked at home like this? Even in 2022 it wasn‚Äôt this bad\n",
      "BRB gonna go chug some nyquil\n",
      "I was there during the Blake era, this current team might be worse! Truly awful!¬†\n",
      "32 in the first half vs South Carolina. I don't know what this program thinks they are but if they don't start firing ppl then enjoy being a doormat for the for seeable future.\n",
      "Gonna need to shut them out to have a chance.\n",
      "Offense has to do something we haven't seen them do all year for us to win this game.\n",
      "My worry here is why does our second and third string suck so bad when a program like ours should have high level recruits waiting to be first string? Like who the fuck is recruiting these kids?\n",
      "If no one's fired for this, boycott until it happens.\n",
      "They are us‚Ä¶defense is great offense sucks.\n",
      "We will only score on defense and offense is a liability. Let‚Äôs just punt on first down\n",
      "Why do we have tight ends and running backs trying to block the best defensive ends in the country? Our offensive staff is inept. I fear this will set the program back for years.\n",
      "When mediocrity is forgiven and not punished it becomes the status quo. \n",
      "\n",
      "You deserve what you tolerate.\n",
      "Can Gasso come over and coach the second half? Im open to trying whatever rn\n",
      "Fire BV at half time\n",
      "Put me in for 0 NIL dollars and I can also turn the ball over at least 3 times in the first quarter\n",
      "Sharp is a bum.\n",
      "This is an embarrassment. I'm just going to watch the train wreck of a season from afar moving forward.\n",
      "\n",
      "\n",
      "This shit is not worth my time or sanity.\n",
      "Personally, I'm excited to see who will be the next Nepo hire on the offensive staff. \n",
      "\n",
      "May make things real easy and just elevate JJF.\n",
      "Did I hear that right, largest deficit at home since the John Blake era? Ouch.\n",
      "No point in going for 2 right now¬†\n",
      "You have the opportunity to get points with a field goal after 3 and out and you...go for it?? OC has to go.\n",
      "\n",
      "\n",
      "Also does anyone else think our other RBs are all better than Barnes?\n",
      "Hey dumbass Seth. If you are going for it on fourth why wouldn‚Äôt you try to get at least three yards on third instead of that ridiculous play you called? Jesus this guy makes me think he is not all there in the head.\n",
      "Any other sickos still watching this with me? JJF is in the booth with Littrell. Clearly that‚Äôs what we needed.\n",
      "God I hope the crowd just boos the shit out of this team\n",
      "I'm also officially on Venables is not the right guy.\n",
      "\n",
      "\n",
      "How many embarrassing and unprepared blowouts is one allowed???\n",
      "Breaking point game\n",
      "[deleted]\n",
      "Am I dreaming\n",
      "Never thought I‚Äôd be excited about an OU punt‚Ä¶\n",
      "Venables is a terrible head coach. Can't keep blaming the OC when there are issues across the board.\n",
      "South Carolina was waiting on that fake. This is embarrassing\n",
      "Sarah Mclaughlin special, again. Roll the clip of the sad puppies\n",
      "My bad guys. I started really watching OU football this season. If I stop, will the curse be lifted?\n",
      "This game was over 6 min into the 1st quarter. How pathetic is that. Sorry a** sh*t. Worst performance I've seen in years.¬†\n",
      "Venables and company gotta go. No, seriously, OU is more concerned about the increased revenue in the SEC. Winning games, not so much\n",
      "Arnold still missing wide open recievers. Make no mistake about it neither QB is that good right now either.\n",
      "And another turnover. What a dumpster fire üî•¬†\n",
      "Well I lasted as long as I could. See you all next year. Pushed plans out to watch this shit. Not doing that anymore.\n",
      "Fake FG to end the half up 32-3 is a classless, punk move.\n",
      "Boomer!!!\n",
      "Hawkins. Nice to know you.\n",
      "Thank god I‚Äôm going fishing today because I don‚Äôt think watching this game would be good for my mental health ¬†\n",
      "Just handing them a win they didn't even have to earn. Fckn pathetic.¬†\n",
      "Alrighty then.\n",
      "What the actual fck was that¬†\n",
      "Our punter is the best part of our team. Let‚Äôs use him.\n",
      "Bounce back game, doomers\n",
      "Bauer Sharp is the worst OU player of my lifetime¬†\n",
      "We‚Äôre fucked\n",
      "Just flew in from Columbia SC. First time in Oklahoma, any suggestions for gameday parking? Night life? Anything must see?\n",
      "Anyone need tickets?\n",
      "Gonna be a long day boys\n",
      "Holy shit\n",
      "Oh boy\n",
      "Loser ass celebrations down 24.\n",
      "The tight ends are terrible. Every game they do something of note that is negative. Drops, missed blocks, drive killing penalties\n",
      "Putting Beville in the game? Definitely trying to clown us\n",
      "GET HAWKINS THE FUCK OFF THE FIELD FFS VENABLES\n",
      "Burn, baby, burn...burning that redshirt. \n",
      "\n",
      "I don't know how I feel about this yet, but this season isn't going anywhere.\n",
      "21-9 USCe. RIP bowl game hopes.\n",
      "View in your timezone:  \n",
      "[Oct 19th, 11:45am CDT][0]  \n",
      "\n",
      "[0]: https://timee.io/20241019T1645?tl=Game%20thread%20-%20South%20Carolina%20(3-3)%20%40%20Oklahoma%20(4-2)%20on%20Oct%2019th%2C%2011%3A45am%20CDT\n",
      "Oh I see Beamer has Riley's cock up his ass like dude you're not a good coach.\n",
      "Did anyone else notice the 12 men on the field during that 2 point conversion?\n",
      "Worst team I‚Äôve ever seen\n",
      "Maybe the SEC was a bad idea\n",
      "I got a 3 day ban from r / cfb for saying ‚Äúthis is the pussiest line I‚Äôve ever seen‚Äù\n",
      "\n",
      "I don‚Äôt know who‚Äôs softer\n",
      "Cocksby90\n",
      "Venables not pulling Hawkins after the 2nd TO just shows how little he understands game flow.\n",
      "Jesus fucking christ\n",
      "Hahahaha\n",
      "Wow, OU really sucks!!!   Don't think they are ready for the SEC....  Even Vandy is better!\n",
      "So Riley apology coming soon\n",
      "Nebraska here we come baby!!\n",
      "As a sc fan this might be my fav game of all time\n",
      "If we can‚Äôt win we don‚Äôt deserve a bowl.\n",
      "\n",
      "We can in theory defeat everyone on our schedule, but this game is the absolute minimum (not counting Maine).\n",
      "100% agree. Even if we did get a diarrhea bowl game 3/4 of the team will opt out\n",
      "I hate how the standard has become just being hopefully we are bowl eligible.\n",
      "Have you ever seen the movie Martyrs? At this point, just embrace the pain and hope it leads to some kind of psychedelic transcendental experience.\n",
      "Well, he‚Äôs in now. God have mercy on our souls\n",
      "Seth Littrell should never be able to show his face in Norman again. I don‚Äôt give a shit if he played here or not. Ex-communicate his bitch ass\n",
      "Destroyed the program all so some assholes could make more money\n",
      "It‚Äôs more than rock bottom.  They are now excavating.\n",
      "Don't look past Maine.\n",
      "1996 I think, according to the broadcast\n",
      "Now it‚Äôs a party!\n",
      "Me too, it sucks to draw that comparison but it sure seems fair given the quality of football from this team\n",
      "Welp\n",
      "That‚Äôs literally every game lol. At this rate, we‚Äôll only beat Maine\n",
      "Hail Mary on every down. We gotta get lucky and draw PI at least once, right?\n",
      "The defense is good. Fire every single offensive coach except Murray. Give BV one more year to turn it around. But I agree, this is a disgrace.\n",
      "The best thing to come out of this game is that Jordan kid. It's time to spend the rest of the season finding the diamonds in the rest of the roster.\n",
      "Can‚Äôt get any worse\n",
      "If you are, you have a deeply unhealthy subconscious\n",
      "This aged like milk\n",
      "Lol\n",
      "NO DOUBT! What the crap?!\n",
      "Bounce back from‚Ä¶ the dog shit offense performance every game this year?\n",
      "GameDay parking runs 20-40 bucks depending on how close you are.  Generally better to Lyft down.  Leaving you'll want to hang out for an hour or two after the game or leave an hour before the end.  Otherwise you'll be sitting in traffic for an hour and paying surge pricing.  \n",
      "\n",
      "There's plenty of drinking and eating available on campus corner, which is about a ten minute walk from the stadium.  Othello's Italian for higher quality food or O'Connell's Irish pub for a more rowdy drinking environment would be my recommendations.\n",
      "\n",
      "Welcome to Norman.\n",
      "Restaurants?\n",
      "Parking at Lloyd noble is free and they charge $5 a piece for a a quick shuttle ride to right in front of the stadium. Just a fair warning it‚Äôs a bitch on the way back. I usually do the 15-20 min walk back after the game.\n",
      "I know right and he is the one to hit the victory formation.  Brutal\n",
      "Yay! A sack! That isn‚Äôt a turnover. We‚Äôre making progress!\n",
      "I have no idea what this means\n",
      "No. Big 12 was a dumpster fire incapable of drawing the talent necessary to win national titles.\n",
      "\n",
      "Hiring a coach simply because of nostalgia for the past was the bad idea.\n",
      "Don‚Äôt be proud. This is like beating up a disabled child.\n",
      "Dude.  It‚Äôs already painful for us.  It‚Äôs a jerk move to make it worse.\n",
      "What theory is that?!\n",
      "I‚Äôm a White Sox fan so sadly I‚Äôm already there. Was hoping college football season would help offer some kind of reprieve.\n",
      "Huh? Are you saying that our move to sec is why our program is imploding? Cuz I think we would struggle against the jawhawks playing like this.\n",
      "Jesus Christ. The fans might literally start a riot. And they should. Let‚Äôs go J6!\n",
      "We‚Äôre about to get shut out\n",
      "Mainer no brainer?\n",
      "Hire this man as the new OC\n",
      "Why except Murray? He seems like one of the worst offenders.\n",
      "Every game he keeps them makes me question his judgement and makes me think he has that jerry jones mindset\n",
      "Yes, the white Jordan. The other one (punt returner) probably needs a new role. \n",
      "\n",
      "Worst thing to come from the game is we won‚Äôt get any more shots of mama Hawkins in the stands.\n",
      "FYI your cell signal will likely disappear near the stadium so some try to get Lyft or uber RIGHT by the stadium. Leave yourself lots of time before & after\n",
      "Go to The Mont for swirls and queso, Victoria's for pasta, Das Boot for German, The Library for good bar food/pizza/craft beers, Scratch for a nicer meal, Levity has good breakfast, Pepe Delgados for good authentic Mexican.\n",
      "If you want Mexican and want to stray from campus Ted‚Äôs on I-35 is 9/10 great (you get free queso). If you want tortillas and atomic salsa you can also ask for them for free!\n",
      "\n",
      "If you want a Steak Sandwhich: Del Rancho! There‚Äôs one on Lindsey that‚Äôs a drive thru only. Or one in Moore that is a sit down!\n",
      "Nah man, South Carolina has had  very little to root for in their history. Let em have this one\n",
      "The same theory that had us thinking we could win\n",
      "Become a Thunder fan! It‚Äôs Oklahoman‚Äôs only hope right now\n",
      "Sorry bro.\n",
      "Exactly. This team would go like 6-6 in the Big 12. We‚Äôd be lucky to beat Maine at this point. Arnold just missed a sure touchdown as I typed that, then he fumbled.\n",
      "No not the reason but now the recovery will be much harder\n",
      "You think? I don‚Äôt know what the backs are supposed to do behind this line when we are so predictable and Tatum seems promising. I would hate to lose the one bright spot we have\n",
      "Definitely possible. I don‚Äôt want to believe that, but you may be right\n",
      "We appreciate it. To be fair, I don‚Äôt hate Oklahoma. I just hate Brent Vegetables, mainly from his Clemson days. So this win was sweet for that reason.\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "\n",
    "# Connect to the specific submission post to scrape data\n",
    "####CHANGE TITLE TO COMPARE OTHER REDDIT FORUMS####\n",
    "submission = reddit.submission(url=\"https://www.reddit.com/r/sooners/comments/1g6qeyu/game_thread_south_carolina_33_oklahoma_42_on_oct/\")\n",
    "\n",
    "# Print the title of the post\n",
    "print(f\"Post Title: {submission.title}\\n\")\n",
    "\n",
    "# Ensure all comments are loaded\n",
    "submission.comments.replace_more(limit=None)\n",
    "\n",
    "# Create a list to store the comment bodies\n",
    "comments_list = []\n",
    "\n",
    "# Loop through all the comments and add their body to the list\n",
    "for comment in submission.comments.list():  # list() to flatten the comment tree\n",
    "    comments_list.append(comment.body)\n",
    "\n",
    "# Print all comments (optional, or you can just use the list later)\n",
    "for comment in comments_list:\n",
    "    print(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c4054d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment analysis\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "302a07f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create variable for sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3a218da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.305, 'neu': 0.496, 'pos': 0.199, 'compound': -0.128}\n",
      "{'neg': 0.0, 'neu': 0.749, 'pos': 0.251, 'compound': 0.3976}\n",
      "{'neg': 0.258, 'neu': 0.417, 'pos': 0.325, 'compound': 0.2023}\n",
      "{'neg': 0.295, 'neu': 0.705, 'pos': 0.0, 'compound': -0.8374}\n",
      "{'neg': 0.275, 'neu': 0.562, 'pos': 0.163, 'compound': -0.25}\n",
      "{'neg': 0.105, 'neu': 0.703, 'pos': 0.191, 'compound': -0.3907}\n",
      "{'neg': 0.108, 'neu': 0.745, 'pos': 0.147, 'compound': 0.2382}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.342, 'neu': 0.658, 'pos': 0.0, 'compound': -0.8075}\n",
      "{'neg': 0.161, 'neu': 0.741, 'pos': 0.098, 'compound': -0.3869}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.325, 'neu': 0.534, 'pos': 0.141, 'compound': -0.5837}\n",
      "{'neg': 0.0, 'neu': 0.814, 'pos': 0.186, 'compound': 0.7817}\n",
      "{'neg': 0.0, 'neu': 0.8, 'pos': 0.2, 'compound': 0.25}\n",
      "{'neg': 0.092, 'neu': 0.734, 'pos': 0.174, 'compound': 0.4215}\n",
      "{'neg': 0.288, 'neu': 0.61, 'pos': 0.102, 'compound': -0.8793}\n",
      "{'neg': 0.536, 'neu': 0.464, 'pos': 0.0, 'compound': -0.7964}\n",
      "{'neg': 0.357, 'neu': 0.317, 'pos': 0.325, 'compound': 0.1531}\n",
      "{'neg': 0.208, 'neu': 0.71, 'pos': 0.082, 'compound': -0.3182}\n",
      "{'neg': 0.242, 'neu': 0.634, 'pos': 0.124, 'compound': -0.6124}\n",
      "{'neg': 0.064, 'neu': 0.687, 'pos': 0.249, 'compound': 0.5831}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.375, 'neu': 0.625, 'pos': 0.0, 'compound': -0.34}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.325, 'neu': 0.675, 'pos': 0.0, 'compound': -0.8769}\n",
      "{'neg': 0.099, 'neu': 0.726, 'pos': 0.175, 'compound': 0.3182}\n",
      "{'neg': 0.172, 'neu': 0.828, 'pos': 0.0, 'compound': -0.4019}\n",
      "{'neg': 0.268, 'neu': 0.732, 'pos': 0.0, 'compound': -0.296}\n",
      "{'neg': 0.0, 'neu': 0.837, 'pos': 0.163, 'compound': 0.7383}\n",
      "{'neg': 0.123, 'neu': 0.828, 'pos': 0.048, 'compound': -0.5719}\n",
      "{'neg': 0.0, 'neu': 0.876, 'pos': 0.124, 'compound': 0.4019}\n",
      "{'neg': 0.0, 'neu': 0.5, 'pos': 0.5, 'compound': 0.8402}\n",
      "{'neg': 0.149, 'neu': 0.851, 'pos': 0.0, 'compound': -0.4836}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'compound': 0.34}\n",
      "{'neg': 0.15, 'neu': 0.724, 'pos': 0.127, 'compound': -0.121}\n",
      "{'neg': 0.416, 'neu': 0.584, 'pos': 0.0, 'compound': -0.6908}\n",
      "{'neg': 0.209, 'neu': 0.608, 'pos': 0.182, 'compound': -0.1027}\n",
      "{'neg': 0.397, 'neu': 0.603, 'pos': 0.0, 'compound': -0.8481}\n",
      "{'neg': 0.324, 'neu': 0.676, 'pos': 0.0, 'compound': -0.8442}\n",
      "{'neg': 0.137, 'neu': 0.669, 'pos': 0.194, 'compound': 0.3818}\n",
      "{'neg': 0.275, 'neu': 0.607, 'pos': 0.117, 'compound': -0.4404}\n",
      "{'neg': 0.5, 'neu': 0.5, 'pos': 0.0, 'compound': -0.4588}\n",
      "{'neg': 0.161, 'neu': 0.759, 'pos': 0.08, 'compound': -0.4854}\n",
      "{'neg': 0.22, 'neu': 0.78, 'pos': 0.0, 'compound': -0.4767}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.588, 'pos': 0.412, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.681, 'pos': 0.319, 'compound': 0.7579}\n",
      "{'neg': 0.211, 'neu': 0.571, 'pos': 0.217, 'compound': 0.0258}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.724, 'pos': 0.276, 'compound': 0.6369}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.313, 'neu': 0.687, 'pos': 0.0, 'compound': -0.6249}\n",
      "{'neg': 0.815, 'neu': 0.185, 'pos': 0.0, 'compound': -0.6597}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.783, 'neu': 0.217, 'pos': 0.0, 'compound': -0.5574}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.697, 'neu': 0.303, 'pos': 0.0, 'compound': -0.7845}\n",
      "{'neg': 0.489, 'neu': 0.511, 'pos': 0.0, 'compound': -0.936}\n",
      "{'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'compound': 0.4019}\n",
      "{'neg': 0.51, 'neu': 0.49, 'pos': 0.0, 'compound': -0.8074}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.641, 'pos': 0.359, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.357, 'neu': 0.524, 'pos': 0.119, 'compound': -0.6131}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.506, 'neu': 0.494, 'pos': 0.0, 'compound': -0.6249}\n",
      "{'neg': 0.412, 'neu': 0.588, 'pos': 0.0, 'compound': -0.5423}\n",
      "{'neg': 0.167, 'neu': 0.833, 'pos': 0.0, 'compound': -0.5574}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.111, 'neu': 0.477, 'pos': 0.412, 'compound': 0.8213}\n",
      "{'neg': 0.0, 'neu': 0.73, 'pos': 0.27, 'compound': 0.1226}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.654, 'pos': 0.346, 'compound': 0.6486}\n",
      "{'neg': 0.068, 'neu': 0.85, 'pos': 0.082, 'compound': 0.1027}\n",
      "{'neg': 0.0, 'neu': 0.865, 'pos': 0.135, 'compound': 0.3612}\n",
      "{'neg': 0.213, 'neu': 0.632, 'pos': 0.155, 'compound': -0.25}\n",
      "{'neg': 0.108, 'neu': 0.721, 'pos': 0.17, 'compound': 0.2263}\n",
      "{'neg': 0.0, 'neu': 0.511, 'pos': 0.489, 'compound': 0.6908}\n",
      "{'neg': 0.205, 'neu': 0.636, 'pos': 0.158, 'compound': -0.3875}\n",
      "{'neg': 0.447, 'neu': 0.553, 'pos': 0.0, 'compound': -0.8062}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.401, 'pos': 0.599, 'compound': 0.4574}\n",
      "{'neg': 0.068, 'neu': 0.702, 'pos': 0.23, 'compound': 0.631}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.797, 'pos': 0.203, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.773, 'pos': 0.227, 'compound': 0.4767}\n",
      "{'neg': 0.239, 'neu': 0.568, 'pos': 0.193, 'compound': -0.3716}\n",
      "{'neg': 0.0, 'neu': 0.877, 'pos': 0.123, 'compound': 0.6369}\n",
      "{'neg': 0.508, 'neu': 0.492, 'pos': 0.0, 'compound': -0.4767}\n",
      "{'neg': 0.345, 'neu': 0.655, 'pos': 0.0, 'compound': -0.5709}\n",
      "{'neg': 0.0, 'neu': 0.545, 'pos': 0.455, 'compound': 0.3612}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4215}\n",
      "{'neg': 0.692, 'neu': 0.308, 'pos': 0.0, 'compound': -0.775}\n",
      "{'neg': 0.359, 'neu': 0.641, 'pos': 0.0, 'compound': -0.6808}\n",
      "{'neg': 0.013, 'neu': 0.912, 'pos': 0.075, 'compound': 0.7184}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.122, 'neu': 0.709, 'pos': 0.169, 'compound': 0.34}\n",
      "{'neg': 0.255, 'neu': 0.745, 'pos': 0.0, 'compound': -0.6249}\n",
      "{'neg': 0.0, 'neu': 0.459, 'pos': 0.541, 'compound': 0.795}\n",
      "{'neg': 0.306, 'neu': 0.694, 'pos': 0.0, 'compound': -0.296}\n",
      "{'neg': 0.301, 'neu': 0.538, 'pos': 0.161, 'compound': -0.5719}\n",
      "{'neg': 0.192, 'neu': 0.449, 'pos': 0.359, 'compound': 0.3818}\n",
      "{'neg': 0.457, 'neu': 0.543, 'pos': 0.0, 'compound': -0.8126}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.127, 'neu': 0.598, 'pos': 0.274, 'compound': 0.4911}\n",
      "{'neg': 0.077, 'neu': 0.768, 'pos': 0.156, 'compound': 0.3313}\n",
      "{'neg': 0.23, 'neu': 0.77, 'pos': 0.0, 'compound': -0.5983}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.524, 'neu': 0.476, 'pos': 0.0, 'compound': -0.296}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.386, 'neu': 0.468, 'pos': 0.146, 'compound': -0.6249}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.108, 'neu': 0.82, 'pos': 0.071, 'compound': -0.34}\n",
      "{'neg': 0.098, 'neu': 0.822, 'pos': 0.08, 'compound': 0.1111}\n",
      "{'neg': 0.0, 'neu': 0.734, 'pos': 0.266, 'compound': 0.891}\n",
      "{'neg': 0.0, 'neu': 0.752, 'pos': 0.248, 'compound': 0.9297}\n",
      "{'neg': 0.072, 'neu': 0.928, 'pos': 0.0, 'compound': -0.1027}\n",
      "{'neg': 0.0, 'neu': 0.703, 'pos': 0.297, 'compound': 0.5859}\n",
      "{'neg': 0.0, 'neu': 0.56, 'pos': 0.44, 'compound': 0.6696}\n",
      "{'neg': 0.565, 'neu': 0.435, 'pos': 0.0, 'compound': -0.0772}\n",
      "{'neg': 0.06, 'neu': 0.734, 'pos': 0.207, 'compound': 0.6597}\n",
      "{'neg': 0.127, 'neu': 0.873, 'pos': 0.0, 'compound': -0.1531}\n",
      "{'neg': 0.184, 'neu': 0.68, 'pos': 0.136, 'compound': -0.25}\n",
      "{'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'compound': 0.25}\n",
      "{'neg': 0.184, 'neu': 0.497, 'pos': 0.319, 'compound': 0.6649}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the sentiment dictionary\n",
    "soonersSentimentDictionary = {}\n",
    "\n",
    "# Initialize index counter\n",
    "index = 1\n",
    "\n",
    "# Calculate sentiment scores and store them in the dictionary\n",
    "for comment in comments_list:\n",
    "    sentiment = sia.polarity_scores(comment)\n",
    "    print(sentiment)\n",
    "    soonersSentimentDictionary[f\"Comment {index}\"] = {\n",
    "        'Positive': sentiment['pos'],\n",
    "        'Negative': sentiment['neg'],\n",
    "        'Neutral': sentiment['neu'],\n",
    "        'Compound': sentiment['compound']\n",
    "    }\n",
    "    # Increase index for next comment\n",
    "    index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7dc34b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Comment Number  Positive Score  Negative Score  Neutral Score  \\\n",
      "0        Comment 1           0.199           0.305          0.496   \n",
      "1        Comment 2           0.251           0.000          0.749   \n",
      "2        Comment 3           0.325           0.258          0.417   \n",
      "3        Comment 4           0.000           0.295          0.705   \n",
      "4        Comment 5           0.163           0.275          0.562   \n",
      "..             ...             ...             ...            ...   \n",
      "132    Comment 133           0.207           0.060          0.734   \n",
      "133    Comment 134           0.000           0.127          0.873   \n",
      "134    Comment 135           0.136           0.184          0.680   \n",
      "135    Comment 136           0.231           0.000          0.769   \n",
      "136    Comment 137           0.319           0.184          0.497   \n",
      "\n",
      "     Compound Score  \n",
      "0           -0.1280  \n",
      "1            0.3976  \n",
      "2            0.2023  \n",
      "3           -0.8374  \n",
      "4           -0.2500  \n",
      "..              ...  \n",
      "132          0.6597  \n",
      "133         -0.1531  \n",
      "134         -0.2500  \n",
      "135          0.2500  \n",
      "136          0.6649  \n",
      "\n",
      "[137 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "# Use pd.DataFrame.from_dict to create a DataFrame from the nested dictionaries\n",
    "df = pd.DataFrame.from_dict(\n",
    "    soonersSentimentDictionary, \n",
    "    orient='index'  # Use 'index' to make the dictionary keys the DataFrame index\n",
    ")\n",
    "\n",
    "# Reset index to turn the index into a column and rename it\n",
    "df.reset_index(inplace=True)\n",
    "df.columns = ['Comment Number', 'Positive Score', 'Negative Score', 'Neutral Score', 'Compound Score']\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "#df.to_csv('OklahomaTennesseeSentiment.csv', index=False)\n",
    "\n",
    "# Print the DataFrame to check the content\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2965f659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment Number</th>\n",
       "      <th>Positive Score</th>\n",
       "      <th>Negative Score</th>\n",
       "      <th>Neutral Score</th>\n",
       "      <th>Compound Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comment 1</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.496</td>\n",
       "      <td>-0.1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comment 2</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.3976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comment 3</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comment 4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.705</td>\n",
       "      <td>-0.8374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comment 5</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.562</td>\n",
       "      <td>-0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Comment 133</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.6597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Comment 134</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.873</td>\n",
       "      <td>-0.1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Comment 135</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.680</td>\n",
       "      <td>-0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Comment 136</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Comment 137</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.6649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Comment Number  Positive Score  Negative Score  Neutral Score  \\\n",
       "0        Comment 1           0.199           0.305          0.496   \n",
       "1        Comment 2           0.251           0.000          0.749   \n",
       "2        Comment 3           0.325           0.258          0.417   \n",
       "3        Comment 4           0.000           0.295          0.705   \n",
       "4        Comment 5           0.163           0.275          0.562   \n",
       "..             ...             ...             ...            ...   \n",
       "132    Comment 133           0.207           0.060          0.734   \n",
       "133    Comment 134           0.000           0.127          0.873   \n",
       "134    Comment 135           0.136           0.184          0.680   \n",
       "135    Comment 136           0.231           0.000          0.769   \n",
       "136    Comment 137           0.319           0.184          0.497   \n",
       "\n",
       "     Compound Score  \n",
       "0           -0.1280  \n",
       "1            0.3976  \n",
       "2            0.2023  \n",
       "3           -0.8374  \n",
       "4           -0.2500  \n",
       "..              ...  \n",
       "132          0.6597  \n",
       "133         -0.1531  \n",
       "134         -0.2500  \n",
       "135          0.2500  \n",
       "136          0.6649  \n",
       "\n",
       "[137 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b090ef41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Compound Score: -0.04591386861313869\n",
      "Median Compound Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "average_compound = df['Compound Score'].mean()\n",
    "\n",
    "# Calculate the median of the compound scores\n",
    "median_compound = df['Compound Score'].median()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Average Compound Score: {average_compound}\")\n",
    "print(f\"Median Compound Score: {median_compound}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed83f864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bd010b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
